---
title: "data cleaning"
author: "Haewon Lee"
format: html
editor: visual
---

## Excel data 읽기

library를 읽어들이고 디렉토리에서 화일이름을 선택

```{r}
library(readxl)   ## Excel file 다루는 library
library(magrittr) ## pipe line operator
dir(pattern = "*.xlsx") -> xlsxfiles  ## directory에서 xlsx file 찾기
xlsxfiles
xlsxfiles[1] -> dfile  ## first file name
```

시트의 숫자가 몇개인지 확인해본다.

```{r}
excel_sheets(path = dfile)
excel_sheets(path = dfile) %>% length 
```

61 sheet 라는 것을 알 수 있다. 시험삼아 첫번째 시트를 읽어본다.

```{r}
read_xlsx(path=dfile, sheet=1) %>% str
```

처음부터 5\~6개의 행은 데이터가 아니라는 것을 알 수 있고 첫번째 열에서 5-6 번째에 "UPLOAD_ID" 가 나오는 부분부터 데이터라는 것을 알 수 있다. 이게 시트마다 다를 수 있기 때문에 찾아야 한다.

```{r}
read_xlsx(path=dfile, sheet=1) %>% 
  .[1:10,1] %>% {which(.=="UPLOAD_ID")} -> sk
sk
```

read_xlsx 명령어에는 skip 이라는 옵션이 있다. 시트 첫부분에 데이터가 아닌 설명들이 있는 경우가 많아서 이걸 제거하기 위한 옵션이다. skip에 5를 입력하면 5번째 행부터 읽으라는 것이 되는데, 이 경우 5번째는 필드이름이기 때문에 6번째부터가 데이터가 된다.

```{r}
read_xlsx(path=dfile, sheet=1,skip = sk+1) -> file1
file1 %>% str
```

sk +1 로 skip을 설정하니까 제대로 된 것을 알 수 있다.

일부 컬럼들은 전부 다 NA 가 나오는 경우가 있다. 전부다 NA인 열은 제거하면 좋겠다.

```{r}
file1 %>% nrow -> rowdf
rowdf
nadf <- NULL ## NA of df
for (k in 1:length(file1)) {
    file1 %>% .[,k] %>% is.na %>% sum %>% c(nadf,.) -> nadf
}
nadf
nadf %>% {which(.<rowdf)} -> notna   ## NA의 갯수가 행의 갯수 보다 작아야 한다.
notna   ## 1  5  8 11
file1[,notna] -> file1  ## 전부 다 NA 가 나오는 것 제거한 상태
file1 %>% str
```

ID duplication detected

```{r}
file1$UPLOAD_ID %>% table %>% as.data.frame %>% .[.$Freq>1,]
```

이런 경우에는 unique 명령어로 중복된 데이터 제거

```{r}
file1 %>% unique -> file1
file1 %>% str
```

이 전과정을 전부 반복루프로 실행 각각의 시트들의 데이터가 얼마나 있는지 알아본다.

```{r}
lengthdf <- NULL
for (s in 1:61) {
  read_xlsx(path=dfile, sheet=s,skip = 0) %>% .[1:10,1] %>% is.na %>% sum -> isna
  if(isna<7){
    read_xlsx(path=dfile, sheet=s,skip = 0) %>% .[1:10,1] %>% {which(.=="UPLOAD_ID")} -> sk
    read_xlsx(path=dfile, sheet=s,skip = sk+1) -> tempdf
    nrow(tempdf) -> rowdf
    nadf <- NULL
    for (k in 1:length(tempdf)) {
      tempdf %>% .[,k] %>% is.na %>% sum %>% c(nadf,.) -> nadf
    }
    nadf %>% {which(.<rowdf)} -> notna
    tempdf[,notna] %>% unique -> tempdf
    lengthdf <- rbind(lengthdf, c(nrow(tempdf),length(tempdf)))
  }
}
lengthdf
```

19번째 시트는 에러가 발생하여 확인해본 결과 데이터가 전혀 없는 시트 그래서 중간에 if(isna\<7) 와 같이 NA 가 7개 이상인 경우에는 시트를 지나가버리도록 함. 따라서 데이터가 전혀 없는 19번째 시트는 건너 뛴다.

lengthdf 의 숫자는 전체 행의 갯수, NA가 아닌 열의 갯수이다. 여기에 시트 번호를 합치면 c(1:18,20:61) 시트 번호에 따른 행의 갯수를 알 수 있다. 그런데, 열의 갯수가 1인 시트는 UPLOAD_ID 열 하나뿐이라는 의미이므로 이것도 제외하여 열의 갯수가 1보다 큰 것만 골라낸다.

```{r}
lengthdf %>% cbind(c(1:18,20:61)) %>% .[.[,2]>1,]
```

결국 시트 중에서 1,2,9,10,20,21,22 번째만 유효하다는 이야기이다.

```{r}
lengthdf %>% cbind(c(1:18,20:61)) %>% .[.[,2]>1,] %>% .[,3] -> selectedsh
```

읽어들여서 데이터프레임으로 만들 sheet 번호들을 selectedsh 라는 변수에 넣고 루프를 돌려서 읽어들이기로 함

```{r}
dflist <- NULL   ## list dataframe을 한군데로 모아 넣을 예정
for (s in selectedsh ) {   ## s : sheet number
  read_xlsx(path=dfile, sheet=s,skip = 0) %>% .[1:10,1] %>% 
    {which(.=="UPLOAD_ID")} -> sk
    read_xlsx(path=dfile, sheet=s,skip = sk+1) -> tempdf
    nrow(tempdf) -> rowdf
    nadf <- NULL
    for (k in 1:length(tempdf)) {
      tempdf %>% .[,k] %>% is.na %>% sum %>% c(nadf,.) -> nadf
    }
    nadf %>% {which(.<rowdf)} -> notna    ## columns not NA 
    tempdf[,notna] %>% unique -> tempdf   ## remove duplicated
    dflist <- c(dflist, list(tempdf))
}
dflist %>% str
```

dflist 라는 리스트에 7개의 데이터프레임이 들어가 있다.

```{r}
dflist[[1]] %>% str
dflist[[2]] %>% str
dflist[[3]] %>% str
dflist[[4]] %>% str
dflist[[5]] %>% str
dflist[[6]] %>% str
dflist[[7]] %>% str
dflist[[1]] %>% colnames %>% t %>% t
dflist[[2]] %>% colnames %>% t %>% t
dflist[[3]] %>% colnames %>% t %>% t
dflist[[4]] %>% colnames %>% t %>% t
dflist[[5]] %>% colnames %>% t %>% t
dflist[[6]] %>% colnames %>% t %>% t
dflist[[7]] %>% colnames %>% t %>% t
```

각각의 data frame의 특성을 알아보고, long form data를 환자의 병록번호에 맞춰 wide form으로 변형해 본다.

```{r}
dflist[[3]] -> lab1 
for (i in 2:8) {
  lab1 %>% .[,i] %>% unique %>% nrow %>% cat(i,")",., "\n")
}
lab1 %>% .[,4] %>% unique ## lab 종류
lab1 %>% .[,8] %>% unique ## unit
lab1 %>% .[,7] %>% unique ## values
lab1 %>% colnames
library(tidyr)
library(DT)
lab1 %>% pivot_wider(names_from =LBTEST, values_from =  LBORRES) %>%
  .[.[,1]=="75661123",] %>% datatable
lab1 %>% pivot_wider(names_from =LBTEST, values_from =  LBORRES) -> widelab1
widelab1 %>% str
widelab1 %>% .[.[,1]=="75661123",7:31] %>% t
### UPLOAD_ID 하나당 LBDTC 날짜 하나 이상인 경우를 찾아보면..
widelab1 %>% .[,c(1,5)] %>% table %>% as.data.frame %>% 
  .[.[,3]>0,1] %>% table %>% as.data.frame %>%  .[.[,2]>1,1] %>% length
```

UPLOAD_ID 하나당 LBDTC 날짜 하나 이상인 경우를 찾아보면 1226건으로 여러개가 나오므로 날짜도 필요

UPLOAD_ID 하나, LBDTC 날짜 하나씩 데이터를 모아서 정리하는 것으로..

```{r}
widelab1 %>% as.data.frame -> widelab1
widelab1 [1,1, drop=T] -> ID1
widelab1 [1,5, drop=T] -> Date1
widelab1 %>% .[.[,1]==ID1 & .[,5]==Date1,] -> data1
data1[,7:31] %>% as.matrix(ncol=25, byrow=T) %>%
  as.numeric %>% matrix(ncol=25, byrow=T) -> mat1
data1[,7:31] %>% colnames -> colnames(mat1)
mat1 %>% apply(MARGIN = 2, FUN = function(x) {mean(x,na.rm=T)}) -> mat2
widelab1[1,c(1,5)] -> df1
mat2 %>% t %>% as.data.frame %>% cbind(df1,.) -> df1
df1
```

특정한 UPLOAD_ID 하나, LBDTC 날짜 하나에 대한 결과를 한줄의 data.frame으로 만드는 과정을 보여줌

이것을 loop로 하여 전체 데이터를 재구성하면 된다.

```{r}
widelab1[,c(1,5)] %>% unique -> iddate  ## 5745
iddate %>%  .[!is.na(.[,2]), ] -> iddate  ## 3805 after removal of NA
widelab1.t <- NULL
for (i in 1:nrow(iddate) ) {
  widelab1 %>% .[.[,1]==iddate[i,1] & .[,5] == iddate[i,2],] -> data1
  data1[,7:31] %>% as.matrix(ncol=25, byrow=T) %>%
  as.numeric %>% matrix(ncol=25, byrow=T) -> mat1
  data1[,7:31] %>% colnames -> colnames(mat1)
  mat1 %>% apply(MARGIN = 2, FUN = function(x) {mean(x,na.rm=T)}) %>% 
    round(2) -> mat2
  iddate[i,] -> df1
  mat2 %>% t %>% as.data.frame %>% cbind(df1,.) -> df1
  widelab1.t %>% rbind(df1) -> widelab1.t
}
widelab1.t %>% .[1000:1010, 1:5]
widelab1.t %>% .[1000:1010, c(1:2,6:12)]
widelab1.t %>% .[1000:1010, c(1:2,13:18)]
widelab1.t %>% .[1000:1010, c(1:2,19:25)]
widelab1.t %>% datatable
```

한줄씩 합치면 데이터가 잘못 들어가는 경우가 발생해서 랩 종류별로 하나씩 합치는 걸로 바꿈. Union join으로 합치기

```{r}
lab.no <- 7
widelab1 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] -> widelab1.t
for (lab.no in 8:31) {
  widelab1 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] %>%
    merge(widelab1.t,., all.x=T,all.y=T,by.x= c("UPLOAD_ID",  "LBDTC")) -> widelab1.t
}
widelab1.t %>% datatable
```

data 숫자가 너무 많아서 보기에 불편함

ID 만으로 통합하면 날짜가 사라지는 문제가 발생함 - 괜찮다면 합치기

```{r}
lab.no <- 7
widelab1 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] -> widelab1.t
for (lab.no in 8:31) {
  widelab1 %>% .[,c(1,lab.no)] %>% .[ !is.na(.[,2]), ] %>%
    merge(widelab1.t,., all.x=T,all.y=T,by.x= c("UPLOAD_ID")) -> widelab1.t
}
widelab1.t %>% datatable
widelab1.t %>%.[,1] %>% unique %>% length
```

ID duplication이 없는 것으로 보아 문제가 없을 것으로 추정됨

이제는 이와 같은 방법으로 나머지 Lab 들도 정리하면 됨

```{r}
dflist[[4]] -> lab2
lab2 %>% str
for (i in 2:8) {
  lab2 %>% .[,i] %>% unique %>% nrow %>% cat(i,")",., "\n")
}
lab2 %>% pivot_wider(names_from = LBETEST, values_from =  LBEORRES) -> widelab2
widelab2 %>% str
lab.no <- 7
widelab2 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] -> widelab2.t
lab.no <- 8
widelab2 %>% .[,c(1,lab.no)] %>% .[ !is.na(.[,2]), ] %>%
    merge(widelab2.t,., all.x=T,all.y=T,by.x= c("UPLOAD_ID")) -> widelab2.t
widelab2.t %>% datatable
widelab2.t %>%.[,1] %>% unique %>% length
```

```{r}
dflist[[5]] -> lab3
lab3 %>% str
for (i in 2:8) {
  lab3 %>% .[,i] %>% unique %>% nrow %>% cat(i,")",., "\n")
}
lab3 %>% pivot_wider(names_from = LBA1TEST, values_from =  LBA1ORRES) -> widelab3
widelab3 %>% str
lab.no <- 8
widelab3 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] -> widelab3.t
for (lab.no in 9:29) {
  widelab3 %>% .[,c(1,lab.no)] %>% .[ !is.na(.[,2]), ] %>%
    merge(widelab3.t,., all.x=T,all.y=T,by.x= c("UPLOAD_ID")) -> widelab3.t
}
widelab3.t %>% datatable
widelab3.t %>%.[,1] %>% unique %>% length
```

```{r}
dflist[[6]] -> lab4
lab4 %>% str
for (i in 2:9) {
  lab4 %>% .[,i] %>% unique %>% nrow %>% cat(i,")",., "\n")
}
lab4 %>% pivot_wider(names_from = LBA2TEST, values_from =  LBA2ORRES) -> widelab4
widelab4 %>% str
lab.no <- 8
widelab4 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] -> widelab4.t
for (lab.no in 9:29) {
  widelab4 %>% .[,c(1,lab.no)] %>% .[ !is.na(.[,2]), ] %>%
    merge(widelab4.t,., all.x=T,all.y=T,by.x= c("UPLOAD_ID")) -> widelab4.t
}
widelab4.t %>% datatable
widelab4.t %>%.[,1] %>% unique %>% length
```

```{r}
dflist[[7]] -> lab5
lab5 %>% str
for (i in 2:9) {
  lab5 %>% .[,i] %>% unique %>% nrow %>% cat(i,")",., "\n")
}
lab5 %>% pivot_wider(names_from = LBA3TEST, values_from =  LBA3ORRES) -> widelab5
widelab5 %>% str
lab.no <- 8
widelab5 %>% .[,c(1,5,lab.no)] %>% .[ !is.na(.[,3]), ] -> widelab5.t
for (lab.no in 9:29) {
  widelab5 %>% .[,c(1,lab.no)] %>% .[ !is.na(.[,2]), ] %>%
    merge(widelab5.t,., all.x=T,all.y=T,by.x= c("UPLOAD_ID")) -> widelab5.t
}
widelab5.t %>% datatable
widelab5.t %>%.[,1] %>% unique %>% length
```

lab1\~lab5 까지 ID duplication 이 없는 것으로 보아 날짜 상관없이 (첫번째 날짜만 존재) merge 해도 문제가 없을 것으로 생각됨
